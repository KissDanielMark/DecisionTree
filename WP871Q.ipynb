{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None,*,value=None):\n",
    "        self.feature = feature # milyen tulajdonság szerint bontunk\n",
    "        self.threshold = threshold  # milyen küszöbértékkel bontunk\n",
    "        self.left = left # bal oldali gyerek\n",
    "        self.right = right # jobb oldali gyerek\n",
    "        self.value = value # érték, ha levélcsomópont\n",
    "        \n",
    "    def is_leaf_node(self):\n",
    "        #ha van értéke, akkor levélcsomópont\n",
    "        return self.value is not None\n",
    "    \n",
    "    def disp(self):\n",
    "        print(f\"\\n\\nNode:\\nfeature\",self.feature, \"\\t\\ntreshold\", self.threshold,\"\\t\\nvalue\", self.value, \"\\nleft\", self.left, \"\\nright\", self.right, sep='\\t')\n",
    "        if self.left is not None:\n",
    "            print(\"LEFT side\")\n",
    "            self.left.disp()\n",
    "        if self.right is not None:\n",
    "            print(\"RIGHT side\")\n",
    "            self.right.disp()\n",
    "\n",
    "class DecisionTree:\n",
    "    #max_depth: REQUIRED - maximális mélység\n",
    "    #min_samples_split: REQUIRED - minimális mintaszám, hogy egy csomópontot szétválasszunk\n",
    "    #min_samples_leaf: REQUIRED - minimális mintaszám, hogy egy csomópont levél legyen\n",
    "    def __init__(self, max_depth=10, min_samples_split=2, min_samples_leaf = 1, number_of_features_used=None, random_state=None, split_criterion=\"information_gain\"):\n",
    "        self.min_samples_split=min_samples_split # minimális mintaszám, hogy egy csomópontot szétválasszunk\n",
    "        self.max_depth=max_depth # fa maximális mélysége\n",
    "        self.number_of_features_used=number_of_features_used # mennyi attribútumot használunk a legjobb bontáshoz, attribútumok egy részhalmaza\n",
    "        self.min_samples_leaf=min_samples_leaf # minimális mintaszám, hogy egy csomópont levél legyen\n",
    "        self.random_state=random_state # random szám generálásához használt seed, reprodukálhatóság miatt\n",
    "        self.split_criterion = split_criterion # bontási kritérium, mse vagy information_gain\n",
    "        self.root=None\n",
    "\n",
    "    #Modeel tanítása\n",
    "    def fit(self, X, y):\n",
    "        # Hiányzó értékek pótlása\n",
    "        mean = np.nanmean(X, axis=0)  # Oszlopok átlaga (kivéve a hiányzó értékeket)\n",
    "        indexs = np.where(np.isnan(X))  # Hiányzó értékek helyei\n",
    "        X[indexs] = np.take(mean, indexs[1])\n",
    "\n",
    "        self.number_of_features_used = X.shape[1] if not self.number_of_features_used else min(X.shape[1],self.number_of_features_used) # ha paraméterként nem adtuk meg semmit, akkor az összes attribútumot használjuk, egyébként a 2 minimumát\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        #rekurzív bontás a legjobb bontással\n",
    "        number_of_samples, number_of_features = X.shape #mintaszám, attribútumok száma\n",
    "        number_of_labels = len(np.unique(y)) #ha ez egy akkor már nem bontjuk tovább -> levélcsomópont\n",
    "        \n",
    "        # 1.) Leállási feltételek\n",
    "        if (depth>=self.max_depth \n",
    "            or number_of_labels==1 \n",
    "            or number_of_samples<self.min_samples_split\n",
    "            or number_of_samples < self.min_samples_leaf):\n",
    "            # ha bármelyik feltétel teljesül, akkor levélcsomópontnál tartunk\n",
    "            # a levélcsomópont értéke a leggyakoribb osztály lesz\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "        \n",
    "        #random_seed beállítása, ha meg lett adva, reprodukálhatóság miatt\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state) #random seed beállítása\n",
    "\n",
    "        features_randomly_chosen = np.random.choice(number_of_features, self.number_of_features_used, replace=False)\n",
    "        #print(\"features_randomly_chosen: \", features_randomly_chosen)\n",
    "\n",
    "        # 2.) Legjobb bontás keresése\n",
    "        best_feature, best_threshold = self._best_split(X, y, features_randomly_chosen) #visszatér a legjobb attribútummal és küszöbértékkel\n",
    "        #print(best_feature)\n",
    "        # 3.) Gyermekek létrehozása és rekurzív hívás\n",
    "        left_indexs, right_indexs = self._split(X[:, best_feature], best_threshold)\n",
    "        left = self._grow_tree(X[left_indexs, :], y[left_indexs], depth+1)\n",
    "        right = self._grow_tree(X[right_indexs, :], y[right_indexs], depth+1)\n",
    "        return Node(feature=best_feature, threshold=best_threshold, left=left, right=right)\n",
    "    \n",
    "    #A leggyakoribb érték meghatározása\n",
    "    def _most_common_label(self, y):\n",
    "        if len(y) == 0:\n",
    "            return None\n",
    "\n",
    "        counter = Counter(map(tuple, y))  # Convert elements to tuples\n",
    "        #print(\"\\n\\n\\nCounter: \", counter)\n",
    "        most_common = counter.most_common(1)\n",
    "        #print(\"Counter.most_common(1): \", most_common)\n",
    "\n",
    "        if len(most_common) == 0:\n",
    "            return None\n",
    "\n",
    "        value = most_common[0][0]  # leggyakoribb érték\n",
    "        return value\n",
    "    \n",
    "    #legjobb vágás keresése\n",
    "    def _best_split(self, X, y, features_randomly_chosen):\n",
    "        best_criterion = None\n",
    "        split_index, split_threshold = None, None\n",
    "\n",
    "        for feature_index in features_randomly_chosen:  #végigmenünk az összes kiválasztott elemen\n",
    "            X_column = X[:, feature_index]#végigpróbáljuk az összes attribútumot 0->random feature index\n",
    "            thresholds = np.unique(X_column)\n",
    "            #print(\"Thresholds: \", thresholds)\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                # minden egyes küszöbértéknél kiszámoljuk a bontás kritériumát\n",
    "                criterion = self._split_criterion(y, X_column, threshold)\n",
    "\n",
    "                if best_criterion is None or criterion > best_criterion: #ha nincs még legjobb kritérium vagy a mostani jobb, akkor frissítjük\n",
    "                    best_criterion = criterion\n",
    "                    split_index = feature_index\n",
    "                    split_threshold = threshold\n",
    "\n",
    "        return split_index, split_threshold\n",
    "\n",
    "    #lehetséges vágási kritériumok használata\n",
    "    def _split_criterion(self, y, X_column, threshold):\n",
    "        if self.split_criterion == \"information_gain\":\n",
    "            return self._information_gain(y, X_column, threshold)\n",
    "        elif self.split_criterion == \"mse\":\n",
    "            return self._mean_squared_error(y, X_column, threshold)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid split criterion!\")\n",
    "\n",
    "    #MSE kritérium számítása - TODO: átnézni\n",
    "    def _mean_squared_error(self, y, X_column, threshold):\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        left_values = y[left_idxs]\n",
    "        right_values = y[right_idxs]\n",
    "        left_mean = np.mean(left_values)\n",
    "        right_mean = np.mean(right_values)\n",
    "        mse = np.mean((left_values - left_mean) ** 2) + np.mean((right_values - right_mean) ** 2)\n",
    "        return mse\n",
    "    \n",
    "    #TODO: átnézni\n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        # parent entropy\n",
    "        parent_entropy = self._entropy(y)\n",
    "\n",
    "        # create children\n",
    "        left_indexs, right_indexs = self._split(X_column, threshold)\n",
    "\n",
    "        if len(left_indexs) == 0 or len(right_indexs) == 0:\n",
    "            return 0\n",
    "        \n",
    "        # calculate the weighted avgerage entropy of children\n",
    "        number_of_samples = len(y)\n",
    "        number_of_samples_left, number_of_samples_right = len(left_indexs), len(right_indexs)\n",
    "        entropy_left, entorpy_right = self._entropy(y[left_indexs]), self._entropy(y[right_indexs])\n",
    "        child_entropy = (number_of_samples_left/number_of_samples) * entropy_left + (number_of_samples_right/number_of_samples) * entorpy_right\n",
    "\n",
    "        # calculate the information gain\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "\n",
    "    #TODO: átnézni\n",
    "    def _entropy(self, y):\n",
    "        flattened_y = np.array(y).flatten()  # Flatten the nested object if needed\n",
    "        histogram = np.bincount(flattened_y.astype(int))  # Compute histogram\n",
    "        ps = histogram / len(flattened_y)\n",
    "        return -np.sum([p * np.log(p) for p in ps if p > 0])\n",
    "\n",
    "    #TODO: átnézni\n",
    "    def _split(self, X_column, split_threshold):\n",
    "        left_idxs = np.argwhere(X_column <= split_threshold).flatten()\n",
    "        right_idxs = np.argwhere(X_column > split_threshold).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "    \n",
    "    #For predicting the output - TODO: átnézni\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "\n",
    "        if node.feature is not None and node.threshold is not None:\n",
    "            if x[node.feature] <= node.threshold:\n",
    "                return self._traverse_tree(x, node.left)\n",
    "            else:\n",
    "                return self._traverse_tree(x, node.right)\n",
    "\n",
    "        return None  # or a default value based on your requirements\n",
    "\n",
    "\n",
    "    \n",
    "    #Fa kiíratása\n",
    "    def print(self):\n",
    "        self.root.disp()\n",
    "        pass\n",
    "\n",
    "    #Fa másfajta megjeeelenítése\n",
    "    def print_tree(self):\n",
    "        self._print_node(self.root)\n",
    "\n",
    "    #TODO: átnézni\n",
    "    def _print_node(self, node, indent=''):\n",
    "        if node is None:\n",
    "            return\n",
    "\n",
    "        if node.is_leaf_node():\n",
    "            print(indent + f\"Leaf: {node.value}\")\n",
    "        else:\n",
    "            print(indent + f\"Feature {node.feature} <= {node.threshold} ?\")\n",
    "            print(indent + \"--> True:\")\n",
    "            self._print_node(node.left, indent + \"    \")\n",
    "            print(indent + \"--> False:\")\n",
    "            self._print_node(node.right, indent + \"    \")\n",
    "\n",
    "    def plot_tree_the_second(self, node, depth, x_offset, y_offset, x_scale):\n",
    "        if node.is_leaf_node():\n",
    "            value = node.value\n",
    "            plt.text(x_offset, y_offset, f'Value: {value:.2f}', fontsize=12, ha='center', va='center',\n",
    "                    bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n",
    "        else:\n",
    "            feature = node.feature\n",
    "            threshold = node.threshold\n",
    "            left_child = node.left\n",
    "            right_child = node.right\n",
    "\n",
    "            plt.text(x_offset, y_offset, f'Feature {feature}\\n<= {threshold:.2f}', fontsize=12, ha='center',\n",
    "                    va='center', bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n",
    "\n",
    "            # Kiszámoljuk a következő csomópontok helyét\n",
    "            next_y_offset = y_offset - 1\n",
    "            next_x_offset_left = x_offset - x_scale / (2 ** (depth + 1))\n",
    "            next_x_offset_right = x_offset + x_scale / (2 ** (depth + 1))\n",
    "\n",
    "            plt.plot([x_offset, next_x_offset_left], [y_offset, next_y_offset], 'k-')\n",
    "            plt.plot([x_offset, next_x_offset_right], [y_offset, next_y_offset], 'k-')\n",
    "\n",
    "            self.plot_tree_the_second(left_child, depth + 1, next_x_offset_left, next_y_offset, x_scale)\n",
    "            self.plot_tree_the_second(right_child, depth + 1, next_x_offset_right, next_y_offset, x_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides   \n",
       "0            7.4              0.70         0.00             1.9      0.076  \\\n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates   \n",
       "0                 11.0                  34.0   0.9978  3.51       0.56  \\\n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (320,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m decision_tree\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     41\u001b[0m \u001b[39m#Döntési fa kiértékelése\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m y_pred \u001b[39m=\u001b[39m decision_tree\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maccuracy\u001b[39m(y_test, y_pred):\n\u001b[1;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msum(y_test \u001b[39m==\u001b[39m y_pred) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y_test)\n",
      "Cell \u001b[0;32mIn[66], line 172\u001b[0m, in \u001b[0;36mDecisionTree.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49marray([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_traverse_tree(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m X])\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (320,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#Minta adatforrás\n",
    "df = pd.read_csv(\"winequality-red.csv\")\n",
    "print(df.shape)\n",
    "display(df.head())\n",
    "X = df[df.columns[:-1]].values\n",
    "y = df[df.columns[:-1]].values\n",
    "\n",
    "#display(\"X:\",X)\n",
    "#display(\"y:\",y)\n",
    "\n",
    "\"\"\"wine = datasets.load_breast_cancer()\n",
    "#display(wine)\n",
    "X = wine.data # adatok\n",
    "y = wine.target # címkék/célváltozók\"\"\"\n",
    "\n",
    "\n",
    "# Előkészítsük a bemeneti adatokat és a címkéket\n",
    "#X = np.array([[1, 2, 3], [4, np.nan, 6], [7, 8, 9]])# Példa bemeneti adatok (a második adat hiányzó értéket tartalmaz)\n",
    "#y = np.array([0, 1, 0]) # Példa címkék\n",
    "\n",
    "\n",
    "\n",
    "#Adatok felosztása tanító és tesztelő halmazra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # 80% tanító, 20% tesztelő\n",
    "\"\"\"display(\"X_train:\",X_train, \"X_train.shape:\",X_train.shape)\n",
    "display(\"y_train:\",y_train, \"y_train.shape:\",y_train.shape)\n",
    "\n",
    "display(\"X_test:\",X_test, \"X_test.shape:\",X_test.shape)\n",
    "display(\"y_test:\",y_test, \"y_test.shape:\",y_test.shape)\"\"\"\n",
    "\n",
    "#Döntési fa tanítása\n",
    "decision_tree = DecisionTree(max_depth=10, split_criterion=\"information_gain\", random_state=0)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "#Döntési fa kiértékelése\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "def accuracy(y_test, y_pred):\n",
    "    return np.sum(y_test == y_pred) / len(y_test)\n",
    "\n",
    "acc = accuracy(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "decision_tree.print_tree()\n",
    "decision_tree.plot_tree_the_second(decision_tree.root, 0, 0, 0, 1)\n",
    "\n",
    "#dt.print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
